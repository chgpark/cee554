\relax 
\citation{staras1972accuracy}
\citation{thomas2005revisiting,cho2010mobile,raghavan2010accurate}
\citation{blanco2008pure,blanco2008efficient,fabresse2013undelayed,shetty2018particle}
\citation{lecun2015deep}
\citation{lenz2015deep,cai2016unified,smith2018object}
\citation{zhu2017target,hamandi2018deepmotion}
\citation{walch2017image}
\citation{elman1990finding}
\citation{walch2017image,gladh2016deep,wang2017deepvo,kendall2015posenet,turan2018deep}
\citation{djugash2006range}
\citation{blanco2008pure}
\citation{yang2012efficient}
\citation{fabresse2013undelayed}
\citation{fabresse2014robust}
\@writefile{toc}{\contentsline {section}{\numberline {I}INTRODUCTION}{1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:example222}{{\caption@xref {fig:example222}{ on input line 101}}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces System overview. A robot localizes its own pose through distance data and the derivative of distance data. \leavevmode {\color  {green}We replace whole probabilistic approach with the deep learning-based ene-to-end mapping.}\relax }}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Works}{1}}
\citation{hochreiter1997long}
\citation{zaremba2014learning}
\citation{tateno2017cnn}
\citation{clark2017vinet}
\citation{wang2017deepvo,kendall2015posenet,turan2018deep}
\citation{gladh2016deep}
\citation{walch2017image,wang2017deepvo}
\citation{ordonez2016deep}
\citation{clark2017vinet}
\citation{luong2015effective}
\citation{jaderberg2015spatial}
\citation{parisotto2018global}
\citation{zhu2018towards}
\citation{xu2017learning}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {II-.1}RO-SLAM}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {II-.2}LSTM}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {II-.3}Localization with Deep Learning}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {II-.4}Applications of LSTMs}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {II-.5}\leavevmode {\color  {red}Attention}}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Our approaches}{2}}
\citation{blanco2008pure,blanco2008efficient}
\citation{luong2015effective}
\newlabel{fig:example}{{\caption@xref {fig:example}{ on input line 133}}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Overall architecture of multimodal stacked Bi-LSTM. \relax }}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-A}Network Architectures}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-B}Multimodal LSTM}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-C}Bidirectional LSTM}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-D}Attention layer}{3}}
\citation{dyer2015transition}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-E}Stacked Architecture}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experiment}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-A}Experimental environment}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-B}Training/Test Dataset}{4}}
\newlabel{setting:sub1}{{\caption@xref {setting:sub1}{ on input line 192}}{4}}
\newlabel{sub@setting:sub1}{{}{4}}
\newlabel{setting:sub2}{{\caption@xref {setting:sub2}{ on input line 198}}{4}}
\newlabel{sub@setting:sub2}{{a}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Experimental system overview. In (a), anchors are attached to landmarks. A tag is attached to a mobile robot. The robot goes on random paths in square space. (b) shows actual experiment situation.\relax }}{4}}
\newlabel{setting}{{3}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \leavevmode {\color  {red}Data syncronizing method. UWB distance data and the global position data are received to different thread. To syncronize time, another independent thread concatenates and saves these two kinds of data.}\relax }}{4}}
\newlabel{fig:sync}{{4}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-C}Sensor calibration}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-D}Training Loss}{4}}
\bibstyle{IEEEtran}
\bibdata{./IEEEabrv,./MyBib}
\bibcite{staras1972accuracy}{1}
\bibcite{thomas2005revisiting}{2}
\bibcite{cho2010mobile}{3}
\bibcite{raghavan2010accurate}{4}
\bibcite{blanco2008pure}{5}
\bibcite{blanco2008efficient}{6}
\bibcite{fabresse2013undelayed}{7}
\bibcite{shetty2018particle}{8}
\bibcite{lecun2015deep}{9}
\bibcite{lenz2015deep}{10}
\bibcite{cai2016unified}{11}
\bibcite{smith2018object}{12}
\bibcite{zhu2017target}{13}
\bibcite{hamandi2018deepmotion}{14}
\bibcite{walch2017image}{15}
\newlabel{calibration:sub1}{{\caption@xref {calibration:sub1}{ on input line 224}}{5}}
\newlabel{sub@calibration:sub1}{{}{5}}
\newlabel{calibration:sub2}{{\caption@xref {calibration:sub2}{ on input line 230}}{5}}
\newlabel{sub@calibration:sub2}{{a}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Sensor calibration overview. (a) shows The formation between a tag and an anchor. (b) shows that four anchors are measured at the same time.\relax }}{5}}
\newlabel{calibration}{{5}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Results}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Root mean squared error of each case\relax }}{5}}
\newlabel{table:RMSE_table}{{I}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion}{5}}
\@writefile{toc}{\contentsline {section}{References}{5}}
\bibcite{elman1990finding}{16}
\bibcite{gladh2016deep}{17}
\bibcite{wang2017deepvo}{18}
\bibcite{kendall2015posenet}{19}
\bibcite{turan2018deep}{20}
\bibcite{djugash2006range}{21}
\bibcite{yang2012efficient}{22}
\bibcite{fabresse2014robust}{23}
\bibcite{hochreiter1997long}{24}
\bibcite{zaremba2014learning}{25}
\bibcite{tateno2017cnn}{26}
\bibcite{clark2017vinet}{27}
\bibcite{ordonez2016deep}{28}
\bibcite{luong2015effective}{29}
\bibcite{jaderberg2015spatial}{30}
\bibcite{parisotto2018global}{31}
\bibcite{zhu2018towards}{32}
\newlabel{fig:trajectory1}{{\caption@xref {fig:trajectory1}{ on input line 243}}{6}}
\newlabel{sub@fig:trajectory1}{{}{6}}
\newlabel{fig:trajectory2}{{\caption@xref {fig:trajectory2}{ on input line 249}}{6}}
\newlabel{sub@fig:trajectory2}{{a}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Trajectories estimated by particle filter-based algorithm and our neural networks' architecture. (a)A trajectory of test1 data (b)A trajectory of test2 data\relax }}{6}}
\newlabel{fig:trajectory}{{6}{6}}
\newlabel{fig:error1}{{\caption@xref {fig:error1}{ on input line 261}}{6}}
\newlabel{sub@fig:error1}{{}{6}}
\newlabel{fig:error2}{{\caption@xref {fig:error2}{ on input line 267}}{6}}
\newlabel{sub@fig:error2}{{a}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The distance error graphes with time step. (a) The Distance error of test 1 data and (b)distance error of test 2 data\relax }}{6}}
\newlabel{fig:error}{{7}{6}}
\bibcite{xu2017learning}{33}
\bibcite{dyer2015transition}{34}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Contribution}{7}}
